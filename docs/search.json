[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "CASA0023 Learning Diary",
    "section": "",
    "text": "Welcome\nHello!\nWelcome to my learning diary!"
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "9  Summary",
    "section": "",
    "text": "In summary, this book has no content whatsoever.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "index.html#about-me",
    "href": "index.html#about-me",
    "title": "CASA0023 Learning Diary",
    "section": "About me",
    "text": "About me\n\nI am Yuxi Zheng from Hubei, China, currently studying for an MSc in Urban Spatial Science at University College London (UCL). I completed my undergraduate studies in Landscape Architecture at Beijing Forestry University (BJFU). I am interested in the application of spatial data analysis in urban ecology. I am passionate about contributing to the protection and improvement of our planet’s ecology by utilizing a diverse array of spatial data for analysis. With a focus on harnessing the power of technology and data-driven insights, I aim to drive positive change and sustainable solutions for our environment.  \n\n\n\n\n\n\n\n\n\n\nContact Information\nEmail: ucfnyz0@ucl.ac.uk / yuxi9662@qq.com\nPhone numbers: +44 07514272307 / +86 13972521203"
  },
  {
    "objectID": "index.html#about-this-book",
    "href": "index.html#about-this-book",
    "title": "CASA0023 Learning Diary",
    "section": "About this book",
    "text": "About this book\n\nIn Spring 2023, while pursuing my studies at UCL, I authored a book that formed a significant part of my assessment for the course CASA0023, focused on Remote Sensing Cities and Environments. This book is a comprehensive guide on remote sensing principles, their applications, and data analysis using R and Google Earth Engine. I used Quarto Book to edit the book and made sure that all the codes are available on my Github repository as open-source for interested readers.  \n\n\nThe book presents a range of topics in the field of remote sensing, including satellite image acquisition and processing, image classification, and change detection. I also discuss various applications of remote sensing in environmental studies, urban planning, and disaster management. To provide readers with hands-on experience, the book includes practical exercises and step-by-step instructions for working with satellite imagery in R and Google Earth Engine."
  },
  {
    "objectID": "index.html#ackownledgement",
    "href": "index.html#ackownledgement",
    "title": "CASA0023 Learning Diary",
    "section": "Ackownledgement",
    "text": "Ackownledgement\nMany thanks to Andrew MacLachlan for his help with this book！"
  },
  {
    "objectID": "week5.html",
    "href": "week5.html",
    "title": "\n5  week5\n",
    "section": "",
    "text": "Google Earth Engine Basic Knowledge"
  },
  {
    "objectID": "week5.html#summary",
    "href": "week5.html#summary",
    "title": "\n5  week5\n",
    "section": "\n5.1 Summary",
    "text": "5.1 Summary\n\n5.1.1 Google Earth Engine Introduction\n\nGoogle Earth Engine is a cloud-based platform for processing and analyzing geospatial data. It combines vast repositories of satellite imagery and other geospatial data with powerful processing tools to enable users to perform complex analysis and generate dynamic visualizations of the Earth’s surface. With its ability to process petabytes of data quickly and efficiently, Google Earth Engine has become an essential tool for scientists, researchers, policymakers, and anyone who is interested in understanding our planet and its environment. Its innovative features and accessibility have made it an important player in the fields of ecology, conservation, urban planning, and disaster response. Google Earth Engine is a game-changer in the world of geospatial analysis and has the potential to transform the way we understand and interact with the world around us.  \n\n\n5.1.2 Difference between Client and Server\nDifference\n\n\n\n\n\n\n\nAspects\nClient\nServer\n\n\n\nFunction\nInteract and visualize geospatial data\nProvide computational power and storage\n\n\nUsage\nBasic analysis and visualization\nAccess and process data programmatically\n\n\nInterface\nWeb-based interactive\nNo graphical interface\n\n\nProcessing\nClient-side\nServer-side with distributed computing\n\n\n\nClient\n\nHere are some examples of projects where GEE applications have been implemented.  \n\nList of awesome GEE apps\nAir quality example\nNDVI slider example\n(Source: Andrew Maclachlan)\nServer\n\nGEE Server provides APIs for developers to access and process data programmatically.  \n\n\n5.1.3 GEE API\n\n5.1.3.1 JavaScript\n\nGee coding based on JavaScript, this is almost all of the Javascript you need to know:  \n\nvar number = 1\n\nvar string = 'Hello, World!'\n\nvar list = [1.23, 8, -3]\nprint(list[2])\n\nvar dictionary = {\n  a: 'Hello',\n  b: 10,\n  c: 0.1343,\n  d: list\n}\n\nprint(dictionary.b)\nprint(number, string, list, dictionary)\n(Source: Andrew Maclachlan)\n\nSome of the basic geospatial data processing steps in GEE and the functions that go into them are as follows:  \n\n\n\n\n\n\n\nGeospatial Processing Steps\nGeospatial Processing Functions\n\n\n\nImage\nband math, clip, convolution, neighborhood, selection\n\n\nImage Collection\nmap, aggregate, filter\n\n\nFeature\nbuffer, centroid, intersection, union, transform\n\n\nFeature Collection\naggregate, filter, flatten, merge, sort\n\n\nFilter\nby bounds, within distance, date, day-of-year, metadata\n\n\nReducer\nmean, linearRegression, percentile, histogram\n\n\nJoin\nsimple, inner, outer, inverted\n\n\nKernel\nsquare, circle, gaussian, sobel, kirsch\n\n\nExport\nto geotiff, to video, to TensorFlow, to map tiles\n\n\nMachine Learning\nCART, random forests, baes, SVM, kmeans, cobweb\n\n\nProjection\ntransform, translate, scale\n\n\n\nCommon basic operations and syntax. Source: youtube.com/watch?v=I-wFYm4Hnhg\n\n5.1.3.2 GEE Code Editor\n\n\n\n\nGEE Code Editor. Source: code.earthengine.google.com/"
  },
  {
    "objectID": "week5.html#application",
    "href": "week5.html#application",
    "title": "\n5  week5\n",
    "section": "\n5.2 Application",
    "text": "5.2 Application\n\n5.2.1 GEE Basic operations\n\nHere are some of the basic operations I perform in gee, including loading image data, scaling images, mosaicing images, clipping images, and texture analysis, pca analysis, etc.  \n\nmy code link: https://code.earthengine.google.com/2d91d811e683d25ff8f3e71a16a8046c\nA series of image enhancement processes\n\n\n\n\nImageEnhance. Source: Yuxi\n\n\n\n\nclipping images\n\n\n\n\nImageEnhance. Source: Yuxi\n\n\n\n\ntexture analysis\n\nGLCM texture analysis describes the texture information in an image by calculating a matrix of co-occurrence of the grey levels of pixels around the same pixel. This texture information can in turn be used to reflect the surface texture, shape, size and other features of the feature, thus providing the base data for subsequent analysis and applications.  \n\n\n\n\n\nImageEnhance. Source: Yuxi\n\n\n\n\npca analysis\n\nPrincipal component analysis (PCA) was performed on a GLCM (grey scale co-occurrence matrix) image of India using Google Earth Engine (GEE) with the following process:  \n\n\n\n\n\nImageEnhance. Source: Yuxi\n\n\n\n\n\nBy performing PCA on a GLCM image of India, we can identify the principal components that explain the most variance in the image. These components can then be used to create a new image that captures the essential features of the original image while removing any noise or redundant information.And it helps to reduce the dimensionality of large datasets.  \n\n\n\n\n\nImageEnhance. Source: Yuxi\n\n\n\n\n\n5.2.2 Examples\nTexture Analysis\n\nLi et al. (2019) used GEE to perform texture analysis on Sentinel-2 imagery for mapping vegetation cover in the Tibetan Plateau. They applied gray-level co-occurrence matrix (GLCM) and local binary patterns (LBP) to extract texture features from the satellite imagery. Then, they used a random forest algorithm to classify the vegetation cover based on these texture features. The results showed that texture analysis improved the classification accuracy compared to using spectral bands alone. This study suggests that texture analysis can be a useful tool for mapping vegetation cover in high-altitude areas.  \n\nPrincipal Component Analysis\n\nGao et al. (2019) used GEE to perform PCA on Sentinel-2 imagery for mapping land cover in the Three Gorges Reservoir Area, China. They applied PCA to reduce the dimensionality of the multivariate data and extract the most important information. Then, they used a support vector machine (SVM) algorithm to classify the land cover based on the principal components. The results showed that PCA improved the classification accuracy compared to using all the spectral bands. This study suggests that PCA can be a useful tool for mapping land cover in complex areas with diverse land cover types.  \n\nConclusion\n\nIn conclusion, texture analysis and PCA are powerful tools for analyzing satellite imagery in urban or ecological environments. Texture analysis can extract spatial patterns and improve classification accuracy, while PCA can reduce dimensionality and extract the most important information. By using these techniques, researchers can better understand and manage urban or ecological environments, ultimately contributing to the protection and preservation of these areas."
  },
  {
    "objectID": "week5.html#reflection",
    "href": "week5.html#reflection",
    "title": "\n5  week5\n",
    "section": "\n5.3 Reflection",
    "text": "5.3 Reflection\n\nIn learning to use Google Earth Engine (GEE), I have found that it has many advantages. Firstly, GEE provides easy access to data and processing tools, making it easy for users to work with remote sensing data in the cloud without having to download and store large amounts of data locally. Secondly, GEE provides a wealth of remote sensing data, tools and algorithms that users can write code in JavaScript to use for data analysis and visualisation. In addition, GEE’s code is sharable, which allows users to share their code and collaborate with others on data analysis and model building. Finally, GEE supports large-scale data processing and distributed computing, allowing users to work with large amounts of data more efficiently.  \n\n\nDuring my studies, I learnt a lot about GEE operations, some of which include data acquisition, data pre-processing, image analysis and visualisation. For example, in data acquisition, I learnt how to acquire remote sensing data such as Sentinel-2, Landsat and MODIS from the GEE data repository and load them into code for analysis. In data pre-processing, I learnt how to perform pre-processing operations such as image cropping, image stitching, image reprojection and image de-clouding. In image analysis, I learnt how to perform operations such as remote sensing classification, texture analysis and principal component analysis.  \n\n\nIn practice, I found that sometimes the code execution did not work or the analysis results were not as expected, when I would try to review the code and data to find out what might have gone wrong, and debug and improve it. At the same time, I also think about why things are going wrong and try to understand the root of the problem so that I can better avoid such problems in the future.  \n\n\nI agree that GEE is a powerful tool for analyzing remote sensing data, and it offers many advantages over traditional methods such as R or SNAP. However, I also believe that there are certain limitations to GEE that need to be addressed. For instance, while GEE can handle large datasets, it requires a stable internet connection, which may not be available in some areas. Additionally, GEE is a cloud-based platform, which means that the user has little control over the hardware and software used for processing the data. This could potentially lead to issues with data security and privacy.  \n\nLi, Z., Feng, X., Zhang, L., Lv, G., Zhou, X., & Liu, Q. (2019). Mapping Vegetation Cover in the Tibetan Plateau Using Texture Analysis of Sentinel-2 Imagery. Remote Sensing, 11(15), 1817.\nGao, Y., Zhang, Y., He, M., & Wu, J. (2019). Mapping Land Cover in the Three Gorges Reservoir Area with Sentinel-2 Imagery Using Principal Component Analysis and Support Vector Machine. Remote Sensing, 11(23), 2829."
  },
  {
    "objectID": "week6.html",
    "href": "week6.html",
    "title": "\n6  week6\n",
    "section": "",
    "text": "Classification I"
  },
  {
    "objectID": "week6.html#summary",
    "href": "week6.html#summary",
    "title": "\n6  week6\n",
    "section": "\n6.1 Summary",
    "text": "6.1 Summary\n\n6.1.1 Basics of remote sensing classification\n\nBefore learning about remote sensing classification, we need to have some basic knowledge of machine learning.  \n\n\n\n\n\nClassificationBasic. Source: Yuxi\n\n\n\n\n\n6.1.1.1 Decision Trees\n\nA decision tree is a flowchart-like structure that represents different possible decisions and their possible consequences. In machine learning, decision trees can be used for classification or regression tasks.  \n\n\nDecision tree classification involves using a decision tree to classify data points into different categories based on their features. The decision tree algorithm uses the features of the data to create a set of rules that can be used to classify new data points.  \n\n\nDecision tree regression, on the other hand, involves using a decision tree to predict a numerical value for a target variable based on the values of several input variables. The decision tree algorithm creates a model that maps input variables to a predicted output value.  \n\n\nIn both cases, decision trees are trained on a set of labeled data, meaning data with known classifications or target values, and then used to predict classifications or target values for new data points. The quality of the model is evaluated based on its accuracy in predicting classifications or target values for the test data.  \n\nClassification\n\n\n\n\nDecisionTreeClassification. Source: scikit-learn\n\n\n\n\n\n\nDecisionTreeClassification. Source: scikit-learn\n\n\n\n\nRegression\n\n\n\n\nDecisionTreeRegression. Source: scikit-learn\n\n\n\n\n\n6.1.1.2 Random Forest\n\nRandom Forest builds multiple decision trees and combines their predictions to improve accuracy and reduce overfitting. It is particularly useful for high-dimensional datasets. The algorithm selects a random subset of the training data and a random subset of the input features for each decision tree, and then combines their predictions through a majority vote or average.  \n\n\n\n\n\nRandomForest. Source: IBM\n\n\n\n\n\n6.1.1.3 Support Vector Machine\n\nSupport Vector Machine (SVM) works by finding the optimal hyperplane that maximally separates the data into different classes. The algorithm selects the hyperplane with the largest margin between the classes, which is achieved by finding the support vectors, or the data points closest to the decision boundary. SVM can handle non-linearly separable data by using kernel functions to map the data to a higher dimensional space.  \n\n\n\n\n\nSupportVectorMachine. Source: SVM\n\n\n\n\n\n6.1.2 Image classification\n\nHImage classification is the task of categorizing an image into a predefined set of classes. This is typically done using machine learning algorithms, such as convolutional neural networks (CNNs), which learn to recognize patterns in images and make predictions based on those patterns. There are several types of image classification methods, including supervised learning, unsupervised learning.  \n\n\n\n\n\nImageClassification. Source: youtube\n\n\n\n\n\n6.1.2.1 Related examples\nclassify land-use types\nZhang et al. (2019) applies image classification to urban land-use classification using remote sensing data. The authors use a combination of deep convolutional neural networks (CNNs) and extreme learning machines (ELMs) to classify land-use types in urban areas. The results show that the proposed method outperforms traditional classification methods in terms of accuracy, and can be used for large-scale land-use mapping and urban planning.\nmonitor land cover change\nLu et al. (2019) uses an object-based convolutional neural network (OB-CNN) to classify land-use types in urban areas using multi-source remote sensing data. The authors demonstrate that the OB-CNN method is effective in capturing the spatial context and spectral information of urban land-use, resulting in higher classification accuracy compared to traditional methods. The results can be used for urban planning and environmental monitoring.\ntrack environmental changes\nLiu et al. (2020) applies image classification to monitor urban forest cover change using remote sensing data. The authors use an OB-CNN method to classify urban forest cover and track changes over time. The results demonstrate the potential of OB-CNN for accurate and efficient monitoring of urban forest cover change, which can be used for urban planning and environmental conservation.\nConclusion\nIn conclusion, image classification can be applied to remote sensing urban and environmental studies to classify land-use types, monitor land cover change, and track environmental changes over time. The use of deep learning methods, such as CNNs and OB-CNN, can improve classification accuracy and efficiency. These results have important implications for urban planning and environmental management."
  },
  {
    "objectID": "week6.html#application",
    "href": "week6.html#application",
    "title": "\n6  week6\n",
    "section": "\n6.2 Application",
    "text": "6.2 Application\n\n6.2.1 Classification Workflow\n\nHere is my application of supervised classification of remotely sensed images in GEE using random forests, and my procedure is as follows:  \n\nmy code link: https://code.earthengine.google.com/007b0dfe5b99cad35fd48c9adc919eca\n\n\n\n\nClassificationExampleI. Source: Yuxi\n\n\n\n\n\n6.2.2 Classification Output\n\nThe results after random forest classification and pixel training and classification, respectively, are obtained as follows:  \n\n\n\n\n\nRF. Source: Yuxi\n\n\n\n\n\n\n\n\nRF_Piexl. Source: Yuxi"
  },
  {
    "objectID": "week6.html#reflection",
    "href": "week6.html#reflection",
    "title": "\n6  week6\n",
    "section": "\n6.3 Reflection",
    "text": "6.3 Reflection\n\nAfter learning about the basics of remote sensing classification using machine learning, as well as image classification methods and their applications in remote sensing, urban and environmental domains, I have gained valuable knowledge and insights.  \n\n\nFirstly, I have learned about the importance of feature selection and extraction in remote sensing classification. Different features, such as spectral, spatial, and textural features, can be used to improve the accuracy of classification results. Machine learning algorithms, such as random forests and support vector machines, can be used to classify remote sensing data based on these features.  \n\n\nSecondly,I have learned about the applications of image classification in various fields, such as urban planning, land use and land cover mapping, and environmental monitoring. These applications have significant implications for understanding and addressing various environmental and societal issues.  \n\n\nMoreover, I have gained an understanding of the challenges involved in remote sensing classification, such as the presence of mixed pixels, noise, and the need for ground truth data. These challenges require careful consideration and evaluation when choosing and implementing classification methods. I have reflected on the limitations and biases that can exist in remote sensing data and how these can impact classification accuracy. It is important to be aware of these limitations and to critically evaluate the data and methods used in remote sensing classification.  \n\nReferences:\nZhang, W., Jiang, H., & Wu, S. (2019). An urban land-use classification method based on deep convolutional neural network and extreme learning machine. International Journal of Remote Sensing, 40(6), 2236-2258.\nLu, L., Li, Y., Fu, X., & Liu, X. (2019). An object-based convolutional neural network for land-use classification using multi-source remote sensing data. Remote Sensing, 11(8), 888.\nLiu, X., Jiao, L., & Guo, Y. (2020). Monitoring urban forest cover change based on object-based convolutional neural network. IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing, 13, 2652-2660."
  },
  {
    "objectID": "week7.html",
    "href": "week7.html",
    "title": "\n7  week7\n",
    "section": "",
    "text": "Classification II"
  },
  {
    "objectID": "week7.html#summary",
    "href": "week7.html#summary",
    "title": "\n7  week7\n",
    "section": "\n7.1 Summary",
    "text": "7.1 Summary\n\n7.1.1 Basics of remote sensing classification\n\nThere are three categories of SubPixel Analysis Object-Based Image Analysis Superpixel, which are distinguished by the following diagram：\n\n\n\n\n\n\n\n\n\nFeature\nSubPixel Analysis\nObject-Based Image Analysis\nSuperpixel\n\n\n\nDefinition\nAnalyzes and classifies each pixel into spectral subunits.\nGroups adjacent pixels into objects and analyzes them based on their properties.\nClusters adjacent pixels with similar characteristics to create more meaningful units.\n\n\nMethod\nEstimates spectral values of subunits using math models and algorithms.\nSegments image into objects, extracts features, and classifies them.\nGenerates superpixels, extracts features, and classifies them.\n\n\nWorkflow\nExtraction, classification, mapping.\nSegmentation, feature extraction, object classification, accuracy assessment.\nPre-processing, superpixel generation, feature extraction, classification.\n\n\nAdvantages\nDetects sub-pixel spectral variations, improves classification accuracy.\nCaptures spatial and contextual information, reduces “salt and pepper” effect.\nReduces data redundancy, simplifies analysis, preserves spatial resolution.\n\n\nDisadvantages\nSensitive to noise, requires high computational resources.\nCan result in over- or under-segmentation, requires careful selection of parameters.\nCan over- or under-segment, resulting objects may not be meaningful.\n\n\n\n7.1.2 Accuracy Assessment Methods in Remote Sensing Classification\n\n\n\n\nAccuracyAssessment. Source: Yuxi\n\n\n\n\n\nThe mind map shows that accuracy assessment methods in remote sensing classification can be categorized into four main categories: overall accuracy evaluation, confusion matrix evaluation, ROC curve evaluation, and sampling methods evaluation.\n\n\nThe first category, overall accuracy evaluation, includes two methods: overall accuracy (OA) and Kappa coefficient (Kappa). The former calculates the percentage of correctly classified pixels, while the latter takes into account the agreement between the classified map and the reference map.\n\n\nThe second category, confusion matrix evaluation, involves constructing a confusion matrix that summarizes the classification results. The two methods included in this category are confusion matrix (CM) and user’s accuracy and producer’s accuracy. The former provides a table that shows the number of correctly and incorrectly classified pixels for each class, while the latter evaluates the accuracy of each class individually.\n\n\nThe third category, ROC curve evaluation, involves using the ROC curve and AUC to evaluate the performance of a classifier. The ROC curve plots the true positive rate against the false positive rate, while AUC measures the area under the ROC curve.\n\n\nThe last category, sampling methods evaluation, includes three subcategories: stratified sampling, cross-validation, and bootstrapping. Stratified sampling involves dividing the study area into strata and sampling each stratum proportionally or non-proportionally. Cross-validation involves splitting the data into training and testing sets and evaluating the classifier’s performance on the testing set. Bootstrapping involves repeatedly sampling with replacement from the original dataset to generate new datasets and evaluate the classifier’s performance on each new dataset."
  },
  {
    "objectID": "week7.html#application",
    "href": "week7.html#application",
    "title": "\n7  week7\n",
    "section": "\n7.2 Application",
    "text": "7.2 Application\n\n7.2.1 Clssification Example\n\nSubPixel Analysis, Object-Based Image Analysis and Superpixel Analysis are performed on remote sensing images and produce some results： \n\nmy code link: https://code.earthengine.google.com/595af734bc6965a6f51a15aefd5a7dfb\n\n\n\n\nClassificationII. Source: Yuxi\n\n\n\n\n\n7.2.2 Clssification Application\nHerold et al. (2016) apply object-based image analysis and superpixel segmentation to map urban land cover from high-resolution aerial imagery. They compare their results to traditional per-pixel methods and find that their approach is more accurate in identifying complex urban features such as small parks and residential areas. The paper’s contribution is to provide a more efficient and accurate method for mapping urban land cover, which can aid in urban planning and management.\nKhan et al. (2013) apply subpixel analysis to hyperspectral imagery to map urban vegetation at the sub-pixel level. They compare their results to traditional pixel-based methods and find that their approach is more accurate in identifying vegetation in urban environments with low vegetation cover. The paper’s contribution is to provide a more accurate method for mapping urban vegetation, which can aid in urban planning and management.\nGoetz et al. (2018) apply object-based image analysis to map urban trees using LiDAR and multispectral imagery. They find that their approach is more accurate in identifying individual trees and their characteristics, such as height and crown size, compared to traditional pixel-based methods. The paper’s contribution is to provide a more accurate and detailed method for mapping urban trees, which can aid in urban planning and management, as well as in assessing urban forest ecosystems."
  },
  {
    "objectID": "week7.html#reflection",
    "href": "week7.html#reflection",
    "title": "\n7  week7\n",
    "section": "\n7.3 Reflection",
    "text": "7.3 Reflection\n\nAfter learning about subpixel analysis, object-based image analysis, superpixel analysis methods, as well as accuracy assessment methods in remote sensing classification, I have gained a deeper understanding of the challenges and opportunities in this field.\n\n\nSubpixel analysis is a method for improving the accuracy of land cover mapping by considering the fractional abundance of each class within a pixel. Object-based image analysis and superpixel analysis are two related methods that consider the spatial context of objects in an image and group pixels into objects based on their properties, respectively. These methods have advantages over traditional pixel-based classification, as they can better capture the spatial heterogeneity and complexity of the environment.\n\n\nAccuracy assessment is a critical step in remote sensing classification to evaluate the performance of the classification method. There are several metrics that can be used to assess accuracy, including overall accuracy, kappa coefficient, and user and producer accuracy. These metrics allow for the quantification of errors and uncertainties in the classification results, which is essential for making informed decisions and improving the accuracy of classification.\n\n\nFurthermore, I have learned about the applications of these methods in various fields, including urban and environmental monitoring, land use and land cover mapping, and disaster assessment. These applications have significant implications for understanding and addressing various environmental and societal issues.\n\n\nAs for my future work in improving urban environments, these methods can be useful in analyzing the distribution and changes of land use and land cover in urban areas, identifying urban green spaces, and monitoring urban growth and sprawl. By using accurate and reliable remote sensing classification methods, I can better understand the current state and trends of urban environments and develop targeted interventions to improve their sustainability and resilience.\n\nReferences:\nHerold, S., Atkinson, C., Stevens, J. L., & Doherty, D. C. (2016). Mapping Urban Land Cover Using Object-Based Image Analysis and Superpixel Segmentation. Remote Sensing, 8(6), 501.\nKhan, S. I., Mather, M. G., & Roberts, G. W. (2013). Subpixel Analysis of Hyperspectral Imagery for Urban Vegetation Mapping. Remote Sensing, 5(7), 3191-3218.\nGoetz, P. C., Sun, K., & Zolotoy, B. L. (2018). Object-Based Image Analysis for Mapping Urban Trees Using LiDAR and Multispectral Imagery. Remote Sensing, 10(2), 281."
  },
  {
    "objectID": "week1.html",
    "href": "week1.html",
    "title": "\n1  week1\n",
    "section": "",
    "text": "2 Week1 Getting started with remote sensing"
  },
  {
    "objectID": "week1.html#summary",
    "href": "week1.html#summary",
    "title": "\n1  week1\n",
    "section": "\n2.1 Summary",
    "text": "2.1 Summary\n\n2.1.1 Remote Sensing\n\n2.1.1.1 Definition and Applications of Remote Sensing\nRemote sensing refers to the technology and methods of observing and measuring the Earth’s surface using remote sensing platforms such as satellites and airplanes.\nRemote sensing technology is widely used in natural resource surveying, environmental monitoring, urban planning, agricultural production, weather forecasting, and other fields, providing important support for sustainable development of human society.\n\n\n\n\nSatellites. Source: Industry Tap\n\n\n\n\n\n2.1.1.2 sensors and electromagnetic waves\nTypes of Sensors Used in Remote Sensing\n\n\n\n\n\n\n\n\n\nSensor Type\nSensor Name\nEnergy Source\nMode\nInformation Obtained\n\n\n\nPassive\nLandsat\nReflected\nOptical\nHigh-resolution visible and near-infrared images\n\n\nPassive\nSentinel\nReflected\nOptical\nHigh-resolution visible and near-infrared images\n\n\nPassive\nMODIS\nEmitted\nThermal Infrared\nTemperature and thermal distribution information\n\n\nPassive\nASTER\nEmitted\nThermal Infrared\nTemperature and thermal distribution information\n\n\nActive\nALOS\nEmitted\nRadar\nSurface topography and moisture content information\n\n\nActive\nRADARSAT\nEmitted\nRadar\nSurface topography and moisture content information\n\n\nActive\nICESat\nEmitted\nLiDAR\nSurface elevation and 3D information\n\n\n\nElectromagnetic Waves in Remote Sensing Electromagnetic waves are the energy that travels through space in the form of electric and magnetic fields, including visible light, infrared radiation, microwave radiation, and radio waves. Different types of electromagnetic waves have different wavelengths and frequencies, and can interact with the Earth’s surface and atmosphere in different ways, allowing remote sensing sensors to measure various physical properties of the Earth’s surface and atmosphere. The electromagnetic spectrum is divided into different bands, including the visible band, near-infrared band, shortwave infrared band, thermal infrared band, microwave band, and radio band, each with its own applications in remote sensing.\nScatters In Resolution\n\nInteracting with Earth’s surface\n\n\n\n\nScattering. Source: Julien Chimot, from Bovensmann et al., 2011\n\n\n\n\n\n2.1.2 Remote Sensing Data\nRemote sensing data refers to information about the Earth’s surface and atmosphere that is obtained through remote sensing technologies, such as satellites, airplanes, drones, and ground-based sensors.\nThere are several ways to acquire remote sensing data. One approach is to purchase data from commercial providers who offer a range of satellite and aerial imagery products. Another option is to access publicly available data archives, such as those provided by the United States Geological Survey (USGS) or the European Space Agency (ESA).\n\n2.1.2.1 Types\n\n\n\n\n\n\n\nRemote Sensing Data\nDescription\nExamples\n\n\n\nOptical Image Data\nObtained using optical sensors on remote sensing platforms for high-resolution and multispectral imaging of the Earth’s surface.\nLandsat, Sentinel\n\n\nRadar Image Data\nObtained using radar sensors for imaging of the Earth’s surface, providing ground information at night and under cloud cover.\nALOS, RADARSAT\n\n\nLiDAR Data\nObtained using LiDAR sensors for scanning of the Earth’s surface, providing ground elevation and 3D information.\nLiDAR, ICESat\n\n\nThermal Infrared Data\nObtained using infrared sensors for thermal imaging of the Earth’s surface, providing temperature and thermal distribution information.\nMODIS, ASTER\n\n\n\n2.1.2.2 Resolution Type\n\n\nResolution Type\nDescription\n\n\n\nSpatial\nSize of the smallest detectable object\n\n\nSpectral\nNumber and width of spectral bands\n\n\nRadiometric\nNumber of bits used to represent the data\n\n\nTemporal\nTime interval between image captures\n\n\n\n2.1.3 Processing and Applications of Remote Sensing Data\nRemote sensing data needs to be pre-processed, such as radiometric correction, atmospheric correction, geometric correction, etc., to eliminate the influence of the sensor and environmental factors. The applications of remote sensing data include land cover classification, terrain measurement, vegetation index calculation, ocean and lake monitoring, urban construction planning, and other fields.\n\n2.1.4 Development and Trends of Remote Sensing Technology\nRemote sensing technology has gone through multiple stages from single-band to multi-band, low-resolution to high-resolution, and 2D to 3D. In the future, remote sensing technology will continue to develop in the direction of multi-source data fusion, high-performance computing, intelligent algorithm application, etc., to better serve the needs of various fields, such as climate change monitoring, disaster response, resource management, and so on."
  },
  {
    "objectID": "week1.html#application",
    "href": "week1.html#application",
    "title": "\n1  week1\n",
    "section": "\n2.2 Application",
    "text": "2.2 Application\nThis passage discusses a study that examines the relationship between land use and land cover and thermal environment in Belgrade.\nThe study used Landsat imagery from 1991 to 2019 to monitor spatiotemporal changes in green spaces and land surface temperature.\nThe results showed that there was a fluctuating trend in the normalized difference vegetation index (NDVI) and the normalized difference water index (NDWI), with the highest values recorded in 2019 indicating vegetation recovery in the last decade. There was a significant positive correlation between the spectral vegetation indices and the amount of precipitation during the growing season.\n\n\n\n\nMarković. Source: Monitoring of Spatiotemporal Change of Green Spaces in Relation to the Land Surface Temperature: A Case Study of Belgrade, Serbia Remote Sensing\n\n\n\n\nThe share of vegetated and bare land decreased by 11.74% during the study period, with the most intensive conversion of green and bare land into built-up land cover occurring in the first decade (1991–2000). The reduction in vegetation was associated with an increase in the land surface temperature, indicating a negative correlation between the change in the spectral vegetation indices and change in the LST.\n\n\n\n\nMarković. Source: Monitoring of Spatiotemporal Change of Green Spaces in Relation to the Land Surface Temperature: A Case Study of Belgrade, Serbia Remote Sensing\n\n\n\n\n\n\n\n\nMarković. Source: Monitoring of Spatiotemporal Change of Green Spaces in Relation to the Land Surface Temperature: A Case Study of Belgrade, Serbia Remote Sensing\n\n\n\n\n\n\n\n\nMarković. Source: Monitoring of Spatiotemporal Change of Green Spaces in Relation to the Land Surface Temperature: A Case Study of Belgrade, Serbia Remote Sensing\n\n\n\n\nThe study identified the municipalities that were the most affected in each decade, and the findings are relevant for actions targeting an improvement in urban thermal comfort and climate resilience. The passage also highlights the importance of green spaces in enhancing living conditions, contributing to adaptation to climate change, and biodiversity conservation. The study suggests that changes in green spaces in Belgrade were driven by fluctuations in climate factors, as well as human-induced changes in land use and land cover."
  },
  {
    "objectID": "week1.html#reflection",
    "href": "week1.html#reflection",
    "title": "\n1  week1\n",
    "section": "\n2.3 Reflection",
    "text": "2.3 Reflection\nLearning about remote sensing sensors, electromagnetic waves, and scattering has provided me with a better understanding of the principles behind remote sensing data acquisition. I now know that remote sensing data can be obtained from various sources, including Sentinel and Landsat satellites, and these data can be processed and analyzed using software such as SNAP, QGIS, and R.\nOne of the most important concepts I learned is spectral signature, which refers to the unique pattern of reflectance or absorption of electromagnetic radiation for different materials in various wavelengths. This knowledge can be applied to identify different land cover types, such as vegetation, bare land, and urban areas, which can be useful for urban and environmental monitoring and management.\nAnother useful concept I learned is color composites, which involve combining different spectral bands to create a false-color image that enhances certain features or properties of the scene. This technique can be used to highlight specific land cover types, such as vegetation and water, and can also be used to detect changes in land cover over time.\nMoreover, this knowledge can be useful for my future work in improving urban environments, such as analyzing the distribution of land cover and identifying urban green spaces. By utilizing remote sensing data and techniques, I can gain a better understanding of the current state and trends of urban environments and develop targeted interventions to improve their sustainability and livability.\nMarković M, Cheema J, Teofilović A, Čepić S, Popović Z, Tomićević-Dubljević J and Pause M 2021 Monitoring of Spatiotemporal Change of Green Spaces in Relation to the Land Surface Temperature: A Case Study of Belgrade, Serbia Remote Sensing 13 3846 Online: http://dx.doi.org/10.3390/rs13193846"
  },
  {
    "objectID": "week3.html",
    "href": "week3.html",
    "title": "\n3  week3\n",
    "section": "",
    "text": "Remote sensing data"
  },
  {
    "objectID": "week3.html#summary",
    "href": "week3.html#summary",
    "title": "\n3  week3\n",
    "section": "\n3.1 Summary",
    "text": "3.1 Summary\n\n3.1.1 Remote sensing image Correction\nRemote sensing image correction refers to the process of performing various correction operations on remote sensing images to make the images reflect surface features and object information more accurately. Correction operations usually include geometric correction, radiometric correction and atmospheric correction to remove distortions and errors in remotely sensed images due to the characteristics of the Earth’s surface and atmosphere.\nGeometric correction, radiometric correction, and atmospheric correction are commonly used techniques in remote sensing image correction. Geometric correction aims to remove geometric distortions caused by sensor position, terrain relief, and other factors, while radiometric correction aims to normalize the image pixel values to account for sensor and environmental conditions. Atmospheric correction is used to correct for atmospheric effects that can cause inaccuracies in remote sensing data.\n\n\n\n\nCorrection. Source: Yuxi"
  },
  {
    "objectID": "week3.html#application",
    "href": "week3.html#application",
    "title": "\n3  week3\n",
    "section": "\n3.2 Application",
    "text": "3.2 Application\nThis study aimed to validate the benefit of fusing imagery from multiple sensors to assess the impact of landscape changes on ecosystem services (ES) and their economic values in the Long County, Shaanxi Province, China.\nThe researchers used several landscape metrics to assess the local spatial configuration over 15 years (2004–2019) from fused imageries. They also proposed an equivalent monetary metric for estimating the ES values, which could be used in the whole of China.\nThe specific research methodology is shown in the flow chart below：\n\n\n\n\nShuangao. Source: Using Satellite Image Fusion to Evaluate the Impact of Land Use Changes on Ecosystem Services and Their Economic Values Remote Sensing\n\n\n\n\n\n\n\n\nShuangao. Source: Using Satellite Image Fusion to Evaluate the Impact of Land Use Changes on Ecosystem Services and Their Economic Values Remote Sensing\n\n\n\n\nThe study found that the spatial distribution of woodland and grassland increased over time, while the distribution of agriculture farmland and unused land decreased. The overall ES values increased (4.34%) under a benefit transfer approach, mainly concerning woodland and grassland.\n\n\n\n\nShuangao. Source: Using Satellite Image Fusion to Evaluate the Impact of Land Use Changes on Ecosystem Services and Their Economic Values Remote Sensing\n\n\n\n\nThe study also highlighted the need for local authorities and environmental practitioners to balance the economic benefits and ecological gains in different landscapes to achieve sustainable development from local to regional scales. The study recommends that the conversion of forest and agricultural land into urban areas must be done through less environmental impact, taking into account the new standards of environmentally friendly cities and smart cities.\n\n\n\n\nShuangao. Source: Using Satellite Image Fusion to Evaluate the Impact of Land Use Changes on Ecosystem Services and Their Economic Values Remote Sensing\n\n\n\n\nOverall, the study found an improvement in the spatial distribution of landscape types and ES evaluated during the 15 years of the study period, with woodland and grassland accounting for most of the improvement.\n\n\n\n\nShuangao. Source: Using Satellite Image Fusion to Evaluate the Impact of Land Use Changes on Ecosystem Services and Their Economic Values Remote Sensing"
  },
  {
    "objectID": "week3.html#reflection",
    "href": "week3.html#reflection",
    "title": "\n3  week3\n",
    "section": "\n3.3 Reflection",
    "text": "3.3 Reflection\nRapid land use change is a major challenge for environmental management today, requiring the integration of economic and ecological objectives into landscape planning and the search for cost-effective conservation strategies.\nImage fusion has the benefit of assessing the impact of landscape change on ecosystem services and economic values, which can help develop better conservation strategies.\nBy applying multiple landscape metrics and machine learning algorithms to remotely sensed imagery from 2004-2019, this study found an overall improvement in landscape types and ecosystem services in Chang County, but there is still an impact of built-up land on agricultural and grassland land conversion.\nBy improving the diversity and connectivity of landscape types, species diversity and ecological connectivity can be promoted, which has positive implications for the maintenance and promotion of biome structure.\nGovernments should balance economic benefits and ecological gains to achieve sustainable development from the local to the regional scale.\nIn future urban construction, a more environmentally friendly approach should be considered, such as building environmentally friendly cities and smart cities, prioritising the use of clean energy, building energy efficient buildings and expanding green cover to reduce damage to the natural environment.\nThis study provides important insights into how to assess and protect ecosystem services, and suggests that we should pay more attention to ecological conservation and sustainable development.\nTranslated with www.DeepL.com/Translator (free version)\nShuangao W, Padmanaban R, Mbanze A A, Silva J M N, Shamsudeen M, Cabral P and Campos F S 2021 Using Satellite Image Fusion to Evaluate the Impact of Land Use Changes on Ecosystem Services and Their Economic Values Remote Sensing 13 851 Online: http://dx.doi.org/10.3390/rs13050851"
  },
  {
    "objectID": "week8.html",
    "href": "week8.html",
    "title": "\n8  week8\n",
    "section": "",
    "text": "9 UHI Policy"
  },
  {
    "objectID": "week8.html#summary",
    "href": "week8.html#summary",
    "title": "\n8  week8\n",
    "section": "\n9.1 Summary",
    "text": "9.1 Summary\n\n9.1.1 What are Heat Islands?\nUrban areas, where these structures are highly concentrated and greenery is limited, become “islands” of higher temperatures relative to outlying areas. These pockets of heat are referred to as “heat islands.” City temperatures are often higher than those of nearby rural areas.\n\n\n\n\nNYC. Source: NYC\n\n\n\n\n\n9.1.2 Causes of UHI effect\nReduced Natural Landscapes in Urban Areas. Urban Material Properties. Urban Geometry. Heat Generated from Human Activities. Weather and Geography.\n\n\n\n\nNYC. Source: NYC\n\n\n\n\n\n9.1.3 Challenges NYC Face\nThe New York City Panel on Climate Change (NPCC) projects up to a 5.7°F increase in New York City (NYC) average temperatures and a doubling of the number of days above 90°F by the 2050s.\n\n\n\n\nNYC. Source: NYC\n\n\n\n\nNew York City faces many social, environmental, economic and infrastructural risks due to the heat island effect.\n\n\n\n\nNYC. Source: NYC\n\n\n\n\n\n9.1.4 Social impacts\nHeat is the NO.1 weather-related killer in the US (NOAA, 2016). Every year, NYC experiences an average of 450 heat-related emergency department visits, 150 heat-related hospital admissions, and 13 heat-stroke deaths. The City also averages about 115 excess deaths from natural causes exacerbated by extreme heat annually (Matte et. all, 2016).\n\n\n\n\nNYC. Source: NYC\n\n\n\n\n\n\n\n\nNYC. Source: NYC"
  },
  {
    "objectID": "week8.html#application",
    "href": "week8.html#application",
    "title": "\n8  week8\n",
    "section": "\n9.2 Application",
    "text": "9.2 Application\n\n9.2.1 New York policys\nOneNYC 2050 Volume 7 (2019) - Goal: A LIVABLE CLIMATE - INITIATIVE 21: New York City is making changes to its physical environment to promote resiliency and mitigate the most dangerous and destructive climate impacts. Such as wetland and forest restoration, to stabilize shorelines, reduce erosion, act as carbon sinks, and mitigate urban heat island effects.\nSecuring Our Future: Strategies for New York City in the Fight Against Climate Change (2020) - Goal: Achieve cooling equity and reduce heat-related deaths - Key strategy: Increase cooling assistance for vulnerable populations\nCool Neighborhoods NYC (2017) - Cool Neighborhoods NYC Monitoring Strategies: Collecting Innovative Data to Deliver Inclusive and Health-focused Climate Policy\n\n9.2.2 International policys\nUnited Nations New Urban Agenda (2015) -Point 54 :Reducing the … air pollution, urban heat island effects and noise.\nUniversal Sustainable Development Goals (2015), SDG 11 Issue Brief (2018) -Goal 11: Make cities and human settlements inclusive, safe, resilient and sustainable. -Cleaner,greener cities: Investing in parks and green spaces in urban areas will help to amelioratethe urban heat island effect and improve air quality in urban spaces.\nSendai Framework for Disaster Risk Reduction 2015-2030 (2015) - Expected outcome: The substantial reduction of disaster risk and losses in lives, livelihoods and health. - Target 7 : Substantially increase the availability of and access to multi-hazard early warning systems and disaster risk information and assessments to people by 2030."
  },
  {
    "objectID": "week8.html#reflection",
    "href": "week8.html#reflection",
    "title": "\n8  week8\n",
    "section": "\n9.3 Reflection",
    "text": "9.3 Reflection\nStudying the policies implemented by major international cities to mitigate urban heat island (UHI) effects has provided me with valuable insights on how urban environments can be managed sustainably. Through my research, I have learned that various UHI mitigation strategies have been implemented, including increasing vegetation cover, promoting green roofs and walls, and improving urban design to enhance ventilation and reduce heat absorption.\nOne of the key takeaways from my research is the importance of interdisciplinary collaboration and community engagement in UHI mitigation efforts. Successful UHI mitigation requires the participation and cooperation of various stakeholders, including urban planners, policymakers, and community members.\nFurthermore, I have also realized the importance of considering the unique social, economic, and environmental contexts of each city when designing and implementing UHI mitigation strategies. Effective UHI mitigation requires a tailored approach that addresses the specific needs and challenges of each city.\nReferences:"
  },
  {
    "objectID": "week4.html",
    "href": "week4.html",
    "title": "\n4  week4\n",
    "section": "",
    "text": "P0licy"
  },
  {
    "objectID": "week4.html#summary",
    "href": "week4.html#summary",
    "title": "\n4  week4\n",
    "section": "\n4.1 Summary",
    "text": "4.1 Summary\n\n\n\n\nNYC. Source: NYC\n\n\n\n\n\n\n\n\nNYC. Source: NYC\n\n\n\n\n\n\n\n\nNYC. Source: NYC\n\n\n\n\nNew York City’s 2050 plan is a comprehensive plan that outlines the city’s goals for sustainability and resiliency. The plan includes measures to address a range of challenges, including climate change, economic growth, and social equity. Some of the key takeaways from the plan that can be helpful for urban planning are:\nLong-term planning is necessary for addressing complex challenges. New York City’s 2050 plan is designed to address the challenges of the future, including climate change and population growth. This shows that long-term planning is necessary for addressing complex challenges that require significant resources and coordination.\nSustainability and resiliency must be integrated into all aspects of urban planning. New York City’s 2050 plan integrates sustainability and resiliency into all aspects of urban planning, including land use, transportation, and building design. This shows that sustainability and resiliency must be integrated into all aspects of urban planning in order to create a truly sustainable and resilient city.\nCommunity engagement is crucial for successful urban planning. New York City’s 2050 plan includes extensive community engagement to ensure that the plan reflects the needs and priorities of the city’s residents. This shows that community engagement is crucial for successful urban planning that is responsive to the needs of the community.\nCollaboration and coordination across multiple sectors and levels of government are necessary for successful urban planning. New York City’s 2050 plan involves collaboration and coordination across multiple sectors and levels of government, including city agencies, private sector partners, and community organizations. This shows that collaboration and coordination are necessary for successful urban planning that involves a wide range of stakeholders and resources.\nThe New York City 2050 plan provides a useful roadmap for urban planning that is focused on sustainability and resiliency, and that involves community engagement, collaboration, and long-term planning. These principles can be applied to urban planning in other cities to create more sustainable and resilient communities."
  },
  {
    "objectID": "week4.html#application",
    "href": "week4.html#application",
    "title": "\n4  week4\n",
    "section": "\n4.2 Application",
    "text": "4.2 Application\nThere are various urban disasters that affect cities around the world. Some of these disasters include:\nUrban pollution Pollution in cities is caused by the release of harmful chemicals into the air, water, and soil. This can result in health problems for people living in the city. To reduce pollution, cities have implemented policies such as:\nPromoting the use of public transportation, bicycles, and walking\nRegulating the emissions from factories and vehicles\nEncouraging the use of renewable energy sources\nImplementing waste management systems to reduce landfill waste\nUrban heat island effect The urban heat island effect occurs when cities are significantly warmer than their surrounding rural areas due to the heat trapped by buildings, roads, and other urban infrastructure. To mitigate this effect, cities have implemented policies such as:\nIncreasing green spaces such as parks, gardens, and urban forests\nPromoting the use of cool roofs and green roofs\nEncouraging the use of natural ventilation in buildings\nPlanting trees to shade sidewalks and streets\nUrban floods Urban floods occur when there is heavy rainfall and the city’s drainage system is unable to handle the water flow. This can cause damage to buildings and infrastructure, and pose a threat to public health. To mitigate urban floods, cities have implemented policies such as:\nImplementing flood prevention measures such as stormwater detention ponds, permeable pavements, and green roofs\nPromoting the use of rain gardens and bioswales to absorb water\nDeveloping early warning systems for floods\nImplementing flood insurance programs\nUrban traffic congestion Urban traffic congestion occurs when there is too much traffic on the roads, leading to slow-moving traffic, increased fuel consumption, and air pollution. To mitigate urban traffic congestion, cities have implemented policies such as:\nPromoting the use of public transportation, bicycles, and walking\nEncouraging carpooling and the use of ride-sharing services\nImplementing road pricing policies to discourage car use during peak hours\nDeveloping intelligent transportation systems to optimize traffic flow\nUrban crime Urban crime is a major issue in many cities around the world. To mitigate urban crime, cities have implemented policies such as:\nIncreasing police presence and surveillance\nDeveloping community policing programs\nImplementing crime prevention through environmental design (CPTED) principles to make neighborhoods safer\nProviding education and job training opportunities to reduce poverty and improve social equity\nIn conclusion, cities face various disasters that require different policy solutions. Through the implementation of appropriate policies, cities can effectively mitigate these disasters and create more livable environments for their residents."
  },
  {
    "objectID": "week4.html#reflection",
    "href": "week4.html#reflection",
    "title": "\n4  week4\n",
    "section": "\n4.3 Reflection",
    "text": "4.3 Reflection\nStudying these urban policies has given me a number of conclusions and reflections:\nGlobal problems require global cooperation to solve them. Many urban policies address global issues, such as climate change and environmental pollution. These problems cannot be solved by individual cities alone and require global cooperation and coordination.\nPolicy implementation requires political support and public participation. Many urban policies require political support and public participation to be implemented. Governments and political leaders need to play an important role in solving urban problems, and the public needs to be actively involved in supporting and promoting policy implementation.\nLong-term planning and sustainability are key to solving urban problems. Many urban policies emphasise long-term planning and sustainability. The future of cities needs to consider long-term sustainability rather than short-term solutions. Policymakers need to consider changes in the coming decades and develop policies that will solve urban problems in the long term.\nSome policies may lead to undesirable consequences. Urban policies need to be considered holistically to ensure that they do not lead to undesirable consequences. For example, some policies may lead to higher house prices or the exclusion of poor people from urban development. Policymakers need to weigh up different interests to ensure that policies are viable and effective.\nPolicies need to be adapted to local contexts and cultures. Different cities have different environmental and cultural contexts, and policy makers need to adapt to local contexts and cultures to ensure that policies are accepted and implemented by local communities."
  },
  {
    "objectID": "week2.html#week-2",
    "href": "week2.html#week-2",
    "title": "2  week2",
    "section": "2.1 Week 2",
    "text": "2.1 Week 2\nIn week 2, we have learnt concepts of Xanringan and Quarto.\n\n2.1.1 Xaringan\nxaringanExtra::embed_xaringan(url = “https://thea89123.github.io/_/“, ratio =”4:3”)"
  }
]